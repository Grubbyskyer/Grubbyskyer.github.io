<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Python3爬虫模拟登录抓取OJ代码 | Xing&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="最近在看《Natural Language Processing with Python》,看到第三章讲用Python从网上爬数据时候，突然就想做个爬虫玩玩了。当然，最先想到的是拿教务管理系统开刀，但是没什么实际意义。玩着游戏时候，又想到在OJ上提交过的代码，有上百个文件，一直很想整理一下，但是一个一个文件去打开网页复制代码，保存到本地，这种事情想想就很蛋疼，还是交给计算机做比较合理。">
<meta property="og:type" content="article">
<meta property="og:title" content="Python3爬虫模拟登录抓取OJ代码">
<meta property="og:url" content="http://yoursite.com/2015/06/10/Python3_spider_to_csuOJ/index.html">
<meta property="og:site_name" content="Xing's Blog">
<meta property="og:description" content="最近在看《Natural Language Processing with Python》,看到第三章讲用Python从网上爬数据时候，突然就想做个爬虫玩玩了。当然，最先想到的是拿教务管理系统开刀，但是没什么实际意义。玩着游戏时候，又想到在OJ上提交过的代码，有上百个文件，一直很想整理一下，但是一个一个文件去打开网页复制代码，保存到本地，这种事情想想就很蛋疼，还是交给计算机做比较合理。">
<meta property="og:image" content="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image1.png">
<meta property="og:image" content="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image2.png">
<meta property="og:image" content="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image3.png">
<meta property="og:image" content="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image4.png">
<meta property="og:image" content="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image5.png">
<meta property="og:image" content="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image6.png">
<meta property="og:image" content="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image7.png">
<meta property="og:image" content="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image8.png">
<meta property="og:image" content="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image9.png">
<meta property="og:image" content="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image10.jpg">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python3爬虫模拟登录抓取OJ代码">
<meta name="twitter:description" content="最近在看《Natural Language Processing with Python》,看到第三章讲用Python从网上爬数据时候，突然就想做个爬虫玩玩了。当然，最先想到的是拿教务管理系统开刀，但是没什么实际意义。玩着游戏时候，又想到在OJ上提交过的代码，有上百个文件，一直很想整理一下，但是一个一个文件去打开网页复制代码，保存到本地，这种事情想想就很蛋疼，还是交给计算机做比较合理。">
  
    <link rel="alternative" href="/atom.xml" title="Xing&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/img/author.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">TIAN Xing</a></h1>
		</hgroup>

		
		<p class="header-subtitle">人生的乐趣就在于永不休止地折腾、折腾、折腾...</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="/instagram">相册</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/Grubbyskyer" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="http://weibo.com/234583516" title="weibo">weibo</a>
					        
								<a class="rss" target="_blank" href="/atom.xml" title="rss">rss</a>
					        
								<a class="zhihu" target="_blank" href="http://www.zhihu.com/people/tian-xing-60-64" title="zhihu">zhihu</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/JSP/" style="font-size: 10px;">JSP</a><a href="/tags/Machine-Learning/" style="font-size: 20px;">Machine Learning</a><a href="/tags/Markdown/" style="font-size: 10px;">Markdown</a><a href="/tags/bitset/" style="font-size: 10px;">bitset</a><a href="/tags/hexo/" style="font-size: 15px;">hexo</a><a href="/tags/mysql/" style="font-size: 10px;">mysql</a><a href="/tags/python3/" style="font-size: 10px;">python3</a><a href="/tags/test/" style="font-size: 10px;">test</a><a href="/tags/爬虫/" style="font-size: 10px;">爬虫</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">中南大学10级，现在本校读研。研究机器学习和自然语言处理相关算法。直男癌O^·^O死♂宅O^·^O极客范</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">TIAN Xing</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="/img/author.jpg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">TIAN Xing</h1>
			</hgroup>
			
			<p class="header-subtitle">人生的乐趣就在于永不休止地折腾、折腾、折腾...</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="/instagram">相册</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Grubbyskyer" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="http://weibo.com/234583516" title="weibo">weibo</a>
			        
						<a class="rss" target="_blank" href="/atom.xml" title="rss">rss</a>
			        
						<a class="zhihu" target="_blank" href="http://www.zhihu.com/people/tian-xing-60-64" title="zhihu">zhihu</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-Python3_spider_to_csuOJ" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/06/10/Python3_spider_to_csuOJ/" class="article-date">
  	<time datetime="2015-06-10T13:06:53.000Z" itemprop="datePublished">Jun 10</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Python3爬虫模拟登录抓取OJ代码
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python3/">python3</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/Python3/">Python3</a>
	</div>


        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>最近在看<a href="http://www.nltk.org/book/" target="_blank" rel="external"><code>《Natural Language Processing with Python》</code></a>,看到第三章讲用Python从网上爬数据时候，突然就想做个爬虫玩玩了。当然，最先想到的是拿教务管理系统开刀，但是没什么实际意义。玩着游戏时候，又想到在OJ上提交过的代码，有上百个文件，一直很想整理一下，但是一个一个文件去打开网页复制代码，保存到本地，这种事情想想就很蛋疼，还是交给计算机做比较合理。</p>
<a id="more"></a>
<h2 id="模拟登录">模拟登录</h2><p>说干就干，打开中南OJ的首页：<a href="http://acm.csu.edu.cn/OnlineJudge/" target="_blank" rel="external">http://acm.csu.edu.cn/OnlineJudge/</a><br><img src="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image1.png" alt="CSU Online Judge"></p>
<p>要是想得到自己提交过的代码的话，首先第一步就是要登录自己的账号了，所以我们需要做一个python的模拟登录的模块。<br>先看一下，我们正常登录账号的过程，点击右上角的<code>Login</code>，然后进入到这个页面：<a href="http://acm.csu.edu.cn/OnlineJudge/loginpage.php" target="_blank" rel="external">http://acm.csu.edu.cn/OnlineJudge/loginpage.php</a><br><img src="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image2.png" alt="Login"></p>
<p>输入账号、密码后点击<code>Submit</code>，验证通过就登录成功了。<br>那我们如何知道浏览器向哪里发送了哪些信息呢？</p>
<blockquote>
<p>发送的地址是：<code>http://acm.csu.edu.cn/OnlineJudge/loginpage.php</code>吗？<br>发送的信息只有：<code>User ID</code>，<code>Password</code>吗？</p>
</blockquote>
<p>为了看到浏览器后台的一些行为，我们需要一款分析工具，由于对<code>chrome</code>的自带的分析工具不太熟悉，我这里用了一款名叫<code>Fiddler</code>的工具。<br>打开这个工具，然后在浏览器地址栏输入<a href="http://acm.csu.edu.cn/OnlineJudge/" target="_blank" rel="external">http://acm.csu.edu.cn/OnlineJudge/</a>，可以在<em>Fiddler</em>得到如下的一条200的数据，如图：<br><img src="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image3.png" alt=""></p>
<p>点击右边的<code>[raw]</code>，可以看到一些浏览器发送的<code>Headers</code>信息，这些信息等下会用到。<br><img src="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image4.png" alt=""></p>
<p>这时候我们去到登录界面<a href="http://acm.csu.edu.cn/OnlineJudge/loginpage.php" target="_blank" rel="external">http://acm.csu.edu.cn/OnlineJudge/loginpage.php</a>，输入账号密码，点击<code>Submit</code>登录后，可以在<em>Fiddler</em>里找到一条<code>post</code>请求（最左边的小图标带有一个绿色小箭头），如下图：<br><img src="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image5.png" alt=""></p>
<p>可以看到我们是给<code>http://acm.csu.edu.cn/OnlineJudge/login.php</code>这个地址发送了数据，而不是我们以为的<code>http://acm.csu.edu.cn/OnlineJudge/loginpage.php</code>，那么发送了哪些数据呢？点击右边的<code>WebForms</code>，就可以看到刚才浏览器提交的表单数据了，如图：<br><img src="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image6.png" alt=""></p>
<p>包括我们填写的账号，密码，还有一个<code>submit</code>项，值是<code>Submit</code>，我估计这个值是写死的<code>Submit</code>，而不是从页面上随机生成的，所以这个值我在后面的编程过程中没有处理，而结果也显示是正确的，事实上，后面爬下来页面就知道，这是个<code>submit</code> <code>type</code>，而且它的<code>value</code>默认写的就是<code>Submit</code>。<br>好了，有了这些东西，我们就可以把模拟登录的代码写出来了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模拟登录</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">login</span><span class="params">()</span>:</span></span><br><span class="line">    cj = http.cookiejar.CookieJar()</span><br><span class="line">    pro = urllib.request.HTTPCookieProcessor(cj)</span><br><span class="line">    opener = urllib.request.build_opener(pro)</span><br><span class="line">    header = &#123;</span><br><span class="line">    <span class="string">'Connection'</span>: <span class="string">'Keep-Alive'</span>,</span><br><span class="line">    <span class="string">'Accept'</span>: <span class="string">'text/html, application/xhtml+xml, */*'</span>,</span><br><span class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-Hans-CN,zh-Hans;q=0.7,ja;q=0.3'</span>,</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; LCJB; rv:11.0) like Gecko'</span>,</span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'acm.csu.edu.cn'</span>,</span><br><span class="line">    <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate'</span>,</span><br><span class="line">    <span class="string">'DNT'</span>: <span class="string">'1'</span></span><br><span class="line">    &#125;</span><br><span class="line">    headers = []</span><br><span class="line">    <span class="keyword">for</span> key, value <span class="keyword">in</span> header.items():</span><br><span class="line">        elem = (key, value)</span><br><span class="line">        headers.append(elem)</span><br><span class="line">    opener.addheaders = headers</span><br><span class="line">    url = <span class="string">'http://acm.csu.edu.cn/OnlineJudge/login.php'</span></span><br><span class="line">    myid = <span class="string">'这里填自己的账号'</span></span><br><span class="line">    password = <span class="string">'这里是密码'</span></span><br><span class="line">    postDict = &#123;</span><br><span class="line">        <span class="string">'user_id'</span>: myid,</span><br><span class="line">        <span class="string">'password'</span>: password,</span><br><span class="line">        <span class="string">'submit'</span>: <span class="string">'Submit'</span></span><br><span class="line">    &#125;</span><br><span class="line">    postData = urllib.parse.urlencode(postDict).encode()</span><br><span class="line">    opener.open(url, postData)</span><br><span class="line">    <span class="keyword">return</span> opener</span><br></pre></td></tr></table></figure></p>
<ul>
<li>这里因为我是用<em>Python3</em>做的，所以用的是<code>urllib.request</code>，就相当于2里面的<code>urllib2</code>，因为在3里面<code>urllib2</code>被拆分成了<code>urllib.request</code>+<code>urllib.error</code>。</li>
<li>然后用<code>http.cookiejar</code>来处理浏览器缓存。</li>
<li>这里的<code>headers</code>就是上面在<em>Fiddler</em>里面看到的那些，加上这些<code>headers</code>的作用是，让接收数据请求的后台以为这是一个普通用户通过浏览器界面的正常访问，而不是爬虫之类的恶意请求，简单地说，就是伪装。</li>
<li>加<code>headers</code>的方法在3里面是：<code>opener.addheaders = headers</code>，注意这不是一个方法，而是一个属性，第一次就按2里面的写成<code>opener.add_headers(header)</code>就报错了。</li>
<li><code>url</code>就是我们在<em>Fiddler</em>里面看到的那个地址。</li>
<li><code>postData</code>要用<code>urllib.parse</code>编码成<code>url</code>格式。</li>
<li>最后返回一个<code>opener</code>，再用这个<code>opener</code>去打开其他界面，里面都是有我们的登录信息的。</li>
</ul>
<h2 id="抓取处理数据">抓取处理数据</h2><p>登录之后，我们的AC代码都是在这个界面显示的：<code>http://acm.csu.edu.cn/OnlineJudge/status.php?user_id=你的ID&amp;jresult=4</code> 如下图：<br><img src="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image7.png" alt=""></p>
<p>然后我们点击<code>Language</code>栏下面的<code>C++</code>就能到代码界面了，如图：（这是本屌原来写的一个<em>BFS</em>，画美不看-_-||）<br><img src="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image8.png" alt=""></p>
<p>我们来看一下这个页面的地址：<code>http://acm.csu.edu.cn/OnlineJudge/showsource.php?id=93605</code>， 可以发现只要我们把所有的<code>id</code>拿到了，然后<code>url = http://acm.csu.edu.cn/OnlineJudge/showsource.php?id= + id</code>然后一个一个去<code>opener.open(url)</code>就可以了。</p>
<p>这个<code>id</code>就是上一个界面中的<code>RunID</code>，我们只需要把上一个界面中的<code>RunID</code>全部拿到，写到一个<code>list</code>里面即可。</p>
<p>那如何拿到上一个界面中的<code>RunID</code>呢，我把这个界面爬下来分析一下：<br><img src="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image9.png" alt=""></p>
<p>可以看到，每个<code>&lt;tr&gt;</code>有9个<code>&lt;td&gt;</code>，分别对应页面上的9列，我们需要的信息就在这些<code>&lt;td&gt;</code>里面，那么如何得到这些信息呢？<br>这里用到一个非常好用的第三方库，<code>BeautifulSoup</code>，它可以很方便的分析原始<code>html</code>代码，并通过一些命令得到你想要的值。例如，这里我们用<code>soup.find_all(&#39;td&#39;)</code>得到界面上所有的<code>&lt;td&gt;</code>标签（这里比较巧，所有的<code>&lt;td&gt;</code>标签都是这些数据，没有多余的其他地方的标签），然后9个为一组去处理得到我们想要的信息。具体代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 文件扩展名</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getext</span><span class="params">(ext)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> ext == <span class="string">'C'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'.c'</span></span><br><span class="line">    <span class="keyword">elif</span> ext == <span class="string">'C++'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'.cpp'</span></span><br><span class="line">    <span class="keyword">elif</span> ext == <span class="string">'Java'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'.java'</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'.txt'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pssoup</span><span class="params">(soup)</span>:</span></span><br><span class="line">    items = []</span><br><span class="line">    tdlist = soup.find_all(<span class="string">'td'</span>)</span><br><span class="line">    n = len(tdlist) / <span class="number">9</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(int(n)):</span><br><span class="line">        runid = tdlist[i * <span class="number">9</span>].get_text().strip()</span><br><span class="line">        problemid = tdlist[i * <span class="number">9</span> + <span class="number">2</span>].get_text().strip()</span><br><span class="line">        language = tdlist[i * <span class="number">9</span> + <span class="number">6</span>].get_text().strip()[:-<span class="number">5</span>]</span><br><span class="line">        ext = getext(language)</span><br><span class="line">        submittime = tdlist[i * <span class="number">9</span> + <span class="number">8</span>].get_text().strip()</span><br><span class="line">        submittime = <span class="string">'_'</span>.join((submittime.split(<span class="string">' '</span>)[<span class="number">0</span>], submittime.split(<span class="string">' '</span>)[<span class="number">1</span>].replace(<span class="string">':'</span>,<span class="string">''</span>)))</span><br><span class="line">        items.append((runid,problemid,ext,submittime))</span><br><span class="line">    nexturl = soup.find_all(<span class="string">'a'</span>)[-<span class="number">8</span>].get(<span class="string">'href'</span>)</span><br><span class="line">    <span class="keyword">return</span> items, nexturl</span><br></pre></td></tr></table></figure></p>
<ul>
<li><em>Python3</em>里面的除法得到的是<code>float</code>类型了，所以在<code>range()</code>函数中使用的话，要加上<code>int()</code></li>
<li>用<code>get_text()</code>得到标签里面的内容，用<code>strip()</code>去除两端的空白符</li>
<li><code>runid</code>是上面提到的后面会用在<code>url</code>里的内容，<code>problemid</code>题目编号，<code>language</code>是语言，然后转换为后缀扩展名，<code>submittime</code>是提交时间，因为同一个题目可能有同一种语言的多次提交，后面三个都是为了用于最后的文件命名。</li>
<li>对<code>submittime</code>的小处理，将<code>yyyy-MM-dd hh:mm:ss</code>的形式转换为<code>yyyy-MM-dd_hhmmss</code>，中间的<code>&#39;_&#39;</code>是为了好看，后面的<code>&#39;:&#39;</code>则是一定要删去的，因为文件命名中不允许存在<code>&#39;:&#39;</code>。</li>
<li>用<code>nexturl = soup.find_all(&#39;a&#39;)[-8].get(&#39;href&#39;)</code>得到下一页的链接地址，因为我看了一下，<code>next page</code>总是倒数第8个链接，用<code>get(&#39;href&#39;)</code>得到<code>&lt;a&gt;</code>的<code>href</code>属性的值。</li>
<li>得到<code>nexturl</code>是为了一直把所有的<code>runid</code>搜集完，我们可以用两个指针，一个是当前界面的<code>url</code>，一个是下一界面的<code>url</code>，当这两个指针相等时候，说明到了最后一页了。</li>
</ul>
<p>得到所有的<code>runid</code>并且存在一个<code>list</code>里面之后，就可以抓到代码界面了。从代码界面中得到代码的纯文本，还是用的<code>BeautifulSoup</code>，因为我发现所有的代码都是在一个<code>&lt;pre&gt;</code>标签里，那么一句话搞定<code>code = soup.pre.get_text()</code></p>
<h2 id="本地保存">本地保存</h2><p>得到代码后，写入文件，代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 写入文件</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write</span><span class="params">(filepath, code)</span>:</span></span><br><span class="line">    f = open(filepath, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>, newline=<span class="string">''</span>)</span><br><span class="line">    f.write(code)</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>open()</code>函数里面第二个参数，我写的是<code>&#39;w&#39;</code>，因为我的<code>code</code>都是经过<code>decode(&#39;utf8&#39;)</code>得到的<code>str</code>类型的数据，而不是<code>decode</code>之前的<code>bytes</code>类型，如果你的<code>code</code>是<code>bytes</code>类型，这里要用<code>&#39;wb&#39;</code>。</li>
<li>第三个参数要加上<code>encoding=&#39;utf-8&#39;</code>，因为中文<em>Windows</em>系统默认编码是<code>gbk</code></li>
<li>第四个参数加上<code>newline=&#39;&#39;</code>，否则写出来的代码每一行下面都会多一个空行。</li>
</ul>
<p><font color="red"><strong>完整的代码为：</strong></font><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> http.cookiejar</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对gzip的数据解压</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ungzip</span><span class="params">(data)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        print(<span class="string">'正在解压...'</span>)</span><br><span class="line">        data = gzip.decompress(data)</span><br><span class="line">        print(<span class="string">'解压完毕!'</span>)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">'未经压缩，无需解压！'</span>)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟登录</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">login</span><span class="params">()</span>:</span></span><br><span class="line">    cj = http.cookiejar.CookieJar()</span><br><span class="line">    pro = urllib.request.HTTPCookieProcessor(cj)</span><br><span class="line">    opener = urllib.request.build_opener(pro)</span><br><span class="line">    header = &#123;</span><br><span class="line">    <span class="string">'Connection'</span>: <span class="string">'Keep-Alive'</span>,</span><br><span class="line">    <span class="string">'Accept'</span>: <span class="string">'text/html, application/xhtml+xml, */*'</span>,</span><br><span class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-Hans-CN,zh-Hans;q=0.7,ja;q=0.3'</span>,</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; LCJB; rv:11.0) like Gecko'</span>,</span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'acm.csu.edu.cn'</span>,</span><br><span class="line">    <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate'</span>,</span><br><span class="line">    <span class="string">'DNT'</span>: <span class="string">'1'</span></span><br><span class="line">    &#125;</span><br><span class="line">    headers = []</span><br><span class="line">    <span class="keyword">for</span> key, value <span class="keyword">in</span> header.items():</span><br><span class="line">        elem = (key, value)</span><br><span class="line">        headers.append(elem)</span><br><span class="line">    opener.addheaders = headers</span><br><span class="line">    url = <span class="string">'http://acm.csu.edu.cn/OnlineJudge/login.php'</span></span><br><span class="line">    myid = <span class="string">'这里填你的账号'</span></span><br><span class="line">    password = <span class="string">'这里是密码'</span></span><br><span class="line">    postDict = &#123;</span><br><span class="line">        <span class="string">'user_id'</span>: myid,</span><br><span class="line">        <span class="string">'password'</span>: password,</span><br><span class="line">        <span class="string">'submit'</span>: <span class="string">'Submit'</span></span><br><span class="line">    &#125;</span><br><span class="line">    postData = urllib.parse.urlencode(postDict).encode()</span><br><span class="line">    opener.open(url, postData)</span><br><span class="line">    <span class="keyword">return</span> opener</span><br><span class="line"></span><br><span class="line"><span class="comment"># 抓取数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getsoup</span><span class="params">(opener, url)</span>:</span></span><br><span class="line">    data = opener.open(url).read()</span><br><span class="line">    data = ungzip(data).decode(<span class="string">'utf8'</span>)</span><br><span class="line">    soup = BeautifulSoup(data)</span><br><span class="line">    <span class="keyword">return</span> soup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件扩展名</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getext</span><span class="params">(ext)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> ext == <span class="string">'C'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'.c'</span></span><br><span class="line">    <span class="keyword">elif</span> ext == <span class="string">'C++'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'.cpp'</span></span><br><span class="line">    <span class="keyword">elif</span> ext == <span class="string">'Java'</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'.java'</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'.txt'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pssoup</span><span class="params">(soup)</span>:</span></span><br><span class="line">    items = []</span><br><span class="line">    tdlist = soup.find_all(<span class="string">'td'</span>)</span><br><span class="line">    n = len(tdlist) / <span class="number">9</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(int(n)):</span><br><span class="line">        runid = tdlist[i * <span class="number">9</span>].get_text().strip()</span><br><span class="line">        problemid = tdlist[i * <span class="number">9</span> + <span class="number">2</span>].get_text().strip()</span><br><span class="line">        language = tdlist[i * <span class="number">9</span> + <span class="number">6</span>].get_text().strip()[:-<span class="number">5</span>]</span><br><span class="line">        ext = getext(language)</span><br><span class="line">        submittime = tdlist[i * <span class="number">9</span> + <span class="number">8</span>].get_text().strip()</span><br><span class="line">        submittime = <span class="string">'_'</span>.join((submittime.split(<span class="string">' '</span>)[<span class="number">0</span>], submittime.split(<span class="string">' '</span>)[<span class="number">1</span>].replace(<span class="string">':'</span>,<span class="string">''</span>)))</span><br><span class="line">        items.append((runid,problemid,ext,submittime))</span><br><span class="line">    nexturl = soup.find_all(<span class="string">'a'</span>)[-<span class="number">8</span>].get(<span class="string">'href'</span>)</span><br><span class="line">    <span class="keyword">return</span> items, nexturl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 得到代码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getcode</span><span class="params">(soup)</span>:</span></span><br><span class="line">    code = soup.pre.get_text()</span><br><span class="line">    <span class="keyword">return</span> code</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建目录</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makedir</span><span class="params">(filedir)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(filedir):</span><br><span class="line">        os.mkdir(filedir)</span><br><span class="line">    <span class="keyword">return</span> filedir</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件路径</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getfp</span><span class="params">(filedir, filename, ext)</span>:</span></span><br><span class="line">    filepath = filedir + filename + ext</span><br><span class="line">    <span class="keyword">return</span> filepath</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 写入文件</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write</span><span class="params">(filepath, code)</span>:</span></span><br><span class="line">    f = open(filepath, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>, newline=<span class="string">''</span>)</span><br><span class="line">    f.write(code)</span><br><span class="line">    f.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">()</span>:</span></span><br><span class="line">    fileids = []</span><br><span class="line">    opener = login()</span><br><span class="line">    purl = <span class="string">''</span></span><br><span class="line">    nurl = <span class="string">'http://acm.csu.edu.cn/OnlineJudge/status.php?user_id=你的ID&amp;jresult=4'</span></span><br><span class="line">    ourl1 = <span class="string">'http://acm.csu.edu.cn/OnlineJudge/'</span></span><br><span class="line">    ourl2 = <span class="string">'http://acm.csu.edu.cn/OnlineJudge/showsource.php?id='</span></span><br><span class="line">    filedir = <span class="string">'E:/File/coj/'</span></span><br><span class="line">    filedir = makedir(filedir)</span><br><span class="line">    <span class="keyword">while</span> purl != nurl:</span><br><span class="line">        soup = getsoup(opener, nurl)</span><br><span class="line">        items, nexturl = pssoup(soup)</span><br><span class="line">        fileids += items</span><br><span class="line">        purl = nurl</span><br><span class="line">        nurl = ourl1 + nexturl</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> fileids:</span><br><span class="line">        runid,problemid,ext,submittime = item</span><br><span class="line">        filename = <span class="string">'_'</span>.join((problemid,submittime))</span><br><span class="line">        url = ourl2 + runid</span><br><span class="line">        soup = getsoup(opener, url)</span><br><span class="line">        code = getcode(soup)</span><br><span class="line">        filepath = getfp(filedir, filename, ext)</span><br><span class="line">        write(filepath, code)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行</span></span><br><span class="line">start()</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>关于里面的<code>ungzip</code>函数，是因为现在的很多网站为了提高加载速度，都对数据进行了压缩（参见<code>headers</code>里有这么一条<code>&#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;</code>），我们拿到数据的话，要对其进行解压，<em>Python</em>有自带的解压工具，直接<code>import gzip</code>即可。</p>
</blockquote>
<p>最后，晒一下得到的文件：<br><img src="http://7xj2nk.com1.z0.glb.clouddn.com/2015-06-10-image10.jpg" alt=""></p>
<p>由于本屌的翔一般的代码书写能力，这里就不放出这些代码了。</p>
<h2 id="友情提示">友情提示</h2><p>没事不要写个爬虫到处乱逛，本屌的<code>ip</code>已被百度贴吧封禁<font color="red">10</font>天-_-||</p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/10/10/Stanford Machine Learning Week1- -Linear Regression with One Variable/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          Stanford Machine Learning Week1- -Linear Regression with One Variable
        
      </div>
    </a>
  
  
    <a href="/2015/05/15/配置JSP+Servlet+mysql的开发环境/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">配置JSP+Servlet+mysql的开发环境</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到：</span>
		<a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
		<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>



<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="Python3_spider_to_csuOJ" data-title="Python3爬虫模拟登录抓取OJ代码" data-url="http://yoursite.com/2015/06/10/Python3_spider_to_csuOJ/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"grubbyskyer"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 TIAN Xing
    	</div>
      	<div class="footer-right">
      		Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>